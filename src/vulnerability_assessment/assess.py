import logging
import json
import sys # For stderr output
from scapy.all import rdpcap, sniff, Packet # Import necessary scapy parts
from . import feature_extractor
from . import llm_interface # Imports the updated interface
from . import rules
import os # For geteuid check

logger = logging.getLogger(__name__)

# Global counter for live packets (reset in assess_live)
live_packet_count = 0

def assess_pcap(pcap_file_path: str, model_path: str = None):
    """
    Analyzes packets from a PCAP file using the specified LLM model.

    Args:
        pcap_file_path: Path to the PCAP file.
        model_path: Identifier (name or path) for the LLM model. Uses default if None.

    Returns:
        A list of dictionaries, where each dictionary represents a detected vulnerability.
    """
    logger.info(f"Reading packets from {pcap_file_path}...")
    try:
        packets = rdpcap(pcap_file_path)
    except FileNotFoundError:
        logger.error(f"PCAP file not found: {pcap_file_path}")
        raise
    except Exception as e: # Catch scapy errors specifically if needed
        logger.error(f"Error reading PCAP file {pcap_file_path}: {e}")
        raise

    logger.info(f"Read {len(packets)} packets. Starting analysis with LLM: {model_path or llm_interface.MODEL_NAME}")
    all_vulnerabilities = []
    packet_count = 0

    # Ensure model is loaded before processing packets (optional pre-load)
    if not llm_interface.load_llm_model(model_path or llm_interface.MODEL_NAME):
         logger.error("Failed to load LLM model. Aborting PCAP assessment.")
         return [] # Return empty list if model loading fails upfront

    for packet in packets:
        packet_count += 1
        # Pass the pcap file path as the source_id
        features = feature_extractor.extract_features_from_packet(packet, packet_count, source_id=pcap_file_path)
        if features:
            # Call the updated query_llm function
            analysis_result = llm_interface.query_llm(features, model_path or llm_interface.MODEL_NAME)

            # Check the result structure - it includes 'is_vulnerable' and potentially 'error'
            if analysis_result.get("is_vulnerable"): # Check if LLM flagged it
                 vulnerability_report = format_report(features, analysis_result)
                 all_vulnerabilities.append(vulnerability_report)
                 # Log detailed finding
                 logger.warning(f"VULN DETECTED (PCAP): Type='{analysis_result.get('vulnerability_type', 'Unknown')}', Severity='{analysis_result.get('severity', 'N/A')}', Packet={packet_count}, Src={features.get('src_ip')}, Dst={features.get('dst_ip')}")
            elif "error" in analysis_result:
                 logger.error(f"LLM assessment error for packet {packet_count}: {analysis_result['error']}")
            # else: log non-vulnerable if needed: logger.debug(f"Packet {packet_count} assessed as non-vulnerable.")

    logger.info(f"Finished analyzing {pcap_file_path}. Found {len(all_vulnerabilities)} potential vulnerabilities.")
    return all_vulnerabilities

def process_live_packet(packet: Packet, model_path: str = None, log_file: str = None):
    """Callback function for processing each captured live packet."""
    global live_packet_count # Use global counter
    live_packet_count += 1
    # Use interface name or "live" as source_id?
    features = feature_extractor.extract_features_from_packet(packet, live_packet_count, source_id="live_capture")
    if features:
        logger.debug(f"Processing live packet #{live_packet_count} (Src={features.get('src_ip')}, Dst={features.get('dst_ip')})")
        analysis_result = llm_interface.query_llm(features, model_path or llm_interface.MODEL_NAME)

        if analysis_result.get("is_vulnerable"):
            vulnerability_report = format_report(features, analysis_result)
            # Log detailed finding
            logger.warning(f"VULN DETECTED (LIVE): Type='{analysis_result.get('vulnerability_type', 'Unknown')}', Severity='{analysis_result.get('severity', 'N/A')}', Packet={live_packet_count}, Src={features.get('src_ip')}, Dst={features.get('dst_ip')}")

            # Stream results if log file specified
            if log_file:
                try:
                    with open(log_file, 'a') as f:
                        json.dump(vulnerability_report, f)
                        f.write('\n')
                except IOError as e:
                    logger.error(f"Could not write to live log file {log_file}: {e}")
            else:
                # Print structured output to console if no log file
                print(json.dumps(vulnerability_report, indent=2)) # Use print for direct console output in live mode
        elif "error" in analysis_result:
            logger.error(f"LLM assessment error for live packet {live_packet_count}: {analysis_result['error']}")


def assess_live(interface: str, packet_count: int = 0, log_file: str = None, model_path: str = None):
    """
    Analyzes live network traffic using the specified LLM.

    Args:
        interface: Network interface name.
        packet_count: Number of packets to capture (0 for continuous).
        log_file: Path to stream JSON results.
        model_path: Identifier (name or path) for the LLM model. Uses default if None.
    """
    global live_packet_count
    live_packet_count = 0 # Reset counter for each run

    model_id = model_path or llm_interface.MODEL_NAME
    logger.info(f"Starting live capture on {interface}. Packet count limit: {'Infinite' if packet_count == 0 else packet_count}. LLM: {model_id}")

    # Pre-load the model before starting capture
    if not llm_interface.load_llm_model(model_id):
         logger.error("Failed to load LLM model. Aborting live assessment.")
         return # Exit if model loading fails

    try:
        # Define the callback with necessary arguments using lambda or functools.partial
        packet_handler = lambda pkt: process_live_packet(pkt, model_path=model_id, log_file=log_file)

        # Use store=False to avoid keeping packets in memory
        sniff(iface=interface, prn=packet_handler, count=packet_count, store=False)

    except PermissionError:
        logger.error(f"Permission denied for capturing on interface {interface}. Try running with sudo or root privileges.")
        print(f"Error: Permission denied for interface {interface}. Run with sudo/administrator privileges.", file=sys.stderr)
    except OSError as e:
         # Catch specific errors like "No such device"
         logger.error(f"OS error during live capture setup on {interface}: {e}")
         print(f"Error: Could not capture on interface {interface}. Reason: {e}", file=sys.stderr)
    except Exception as e:
        logger.error(f"An unexpected error occurred during live capture on {interface}: {e}", exc_info=True)
        print(f"An unexpected error occurred: {e}", file=sys.stderr)
    finally:
         logger.info("Live analysis finished or interrupted.")


def format_report(features: dict, analysis: dict) -> dict:
    """Combines features and LLM analysis into a structured report."""
    # Use get with defaults for safety, although analysis structure is somewhat validated now
    return {
        "report_id": f"va-report-{features.get('timestamp', 'na').replace(':', '').replace('-', '')}-{features.get('packet_number', 'na')}", # Basic unique ID
        "timestamp": features.get("timestamp"),
        "source_ip": features.get("src_ip"),
        "source_port": features.get("src_port"),
        "destination_ip": features.get("dst_ip"),
        "destination_port": features.get("dst_port"),
        "protocol": features.get("protocol"),
        "vulnerability_type": analysis.get("vulnerability_type", "Unknown LLM Output"),
        "description": analysis.get("description", "No description provided by LLM."),
        "severity": analysis.get("severity", "Unknown"),
        "evidence": {
            "source_description": features.get("source", "Unknown"), # e.g., pcap filename or "live_capture"
            "packet_number": features.get("packet_number"),
            "packet_length": features.get("length"),
            "payload_snippet": features.get("payload_snippet"), # Include snippet as evidence
            # Add other relevant features like flags if available
            "tcp_flags": features.get("tcp_flags"),
        },
        # Ensure mitigation steps is a list
        "mitigation_steps": analysis.get("mitigation_steps", ["No mitigation steps provided by LLM."]) if isinstance(analysis.get("mitigation_steps"), list) else [str(analysis.get("mitigation_steps"))]
    }


def save_report(results: list, output_path: str):
    """Saves the list of vulnerability reports to a JSON file."""
    if not output_path:
        logger.debug("No output path provided, skipping report saving.")
        return

    logger.info(f"Saving report with {len(results)} findings to {output_path}")
    try:
        with open(output_path, 'w') as f:
            json.dump(results, f, indent=2)
        logger.info(f"Report successfully saved.")
    except IOError as e:
        logger.error(f"Failed to write report to {output_path}: {e}")
        print(f"Error: Could not write report to {output_path}", file=sys.stderr)
    except TypeError as e:
         logger.error(f"Failed to serialize report data to JSON: {e}")
         print(f"Error: Could not serialize report data. Check report structure. Error: {e}", file=sys.stderr)


def print_summary(results: list):
    """Prints a summary of findings to the console."""
    if not results:
        print("No potential vulnerabilities identified in this run.")
        return

    print("\n--- Vulnerability Assessment Summary ---")
    for idx, report in enumerate(results):
        print(f"\nFinding {idx+1}:")
        print(f"  Severity: {report.get('severity', 'N/A')}")
        print(f"  Type:     {report.get('vulnerability_type', 'N/A')}")
        print(f"  Source:   {report.get('source_ip', 'N/A')}:{report.get('source_port','*')} -> Dest: {report.get('destination_ip', 'N/A')}:{report.get('destination_port', '*')}")
        print(f"  Protocol: {report.get('protocol', 'N/A')}")
        desc = report.get('description', 'N/A')
        print(f"  Desc:     {desc[:120] + '...' if len(desc) > 120 else desc}") # Truncate long descriptions
        mitigation = report.get('mitigation_steps', ['N/A'])
        # Show first mitigation step, truncated
        first_step = mitigation[0] if mitigation else 'N/A'
        print(f"  Mitigate: {first_step[:100] + '...' if len(first_step) > 100 else first_step}")
    print("--------------------------------------")
    print(f"Total Potential Vulnerabilities Found: {len(results)}")


def list_reports_func(severity: str = None, limit: int = 20):
    """Placeholder function to list reports from storage."""
    # TODO: Implement querying from a database (SQLite, Elasticsearch, etc.)
    logger.info(f"Attempting to list reports (Severity: {severity}, Limit: {limit})... (Not implemented)")
    print("Report listing feature is not yet implemented. Reports need to be stored persistently first.")
    pass